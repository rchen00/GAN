{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exEIDVJ5Vl06"
   },
   "source": [
    "# HW4: Your First GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7W6Hfyc2Vl08"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5xkrkA2oVl09"
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "# Input image dimensions\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Size of the noise vector, used as input to the Generator\n",
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4izTXRTGVl0-"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "W-k77nTjVl0-"
   },
   "outputs": [],
   "source": [
    "def build_generator(img_shape, z_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "### Your code here\n",
    "### BEGIN\n",
    "   # Fully connected layer\n",
    "    model.add(Dense(128, input_dim=z_dim))\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Output layer with tanh activation\n",
    "    model.add(Dense(28 * 28 * 1, activation='tanh'))\n",
    "\n",
    "    # Reshape the Generator output to image dimensions\n",
    "    model.add(Reshape(img_shape))\n",
    "### END\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X7rZoR4Vl0-"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J_UYK6E_Vl0_"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Flatten the input image\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(128))\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Output layer with sigmoid activation\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjxIAWo5Vl0_"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m5qzVWoQVl0_"
   },
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "### Youe code\n",
    "    model = Sequential()\n",
    "### BEGIN\n",
    "   # Combined Generator -> Discriminator model\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "### END\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S_iv9qCkVl1A"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def build_models(use_tf2=False):\n",
    "\n",
    "    # Build and compile the Discriminator\n",
    "    discriminator = build_discriminator(img_shape)\n",
    "    # Build the Generator\n",
    "    generator = build_generator(img_shape, z_dim)\n",
    "    gan = build_gan(generator, discriminator)\n",
    "\n",
    "\n",
    "    return discriminator, generator, gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bLN6HKBkVl1A"
   },
   "outputs": [],
   "source": [
    "# \n",
    "def accuracy(labels, logits):\n",
    "    logits=tf.concat([tf.ones_like(logits)*0.5,logits],1)\n",
    "    p=tf.argmax(logits, axis=1)\n",
    "    p=tf.cast(p,tf.float64)\n",
    "    labels=tf.reshape(labels,[-1])\n",
    "    acc=tf.reduce_sum(tf.cast(tf.equal(labels, p),tf.float64))\n",
    "    return acc/logits.shape[0]\n",
    "\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_D(model,images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "      logits = model(images, training=True)\n",
    "      #print(logits.shape)\n",
    "      loss = bce(labels, logits)\n",
    "    gradients= tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    acc=accuracy(labels, logits)\n",
    "    return loss,acc\n",
    "@tf.function\n",
    "def train_G(D_model,G_model,z, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "      images=G_model(z)\n",
    "      logits = D_model(images, training=True)\n",
    "      loss = bce(labels, logits)\n",
    "    gradients= tape.gradient(loss, G_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, G_model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Uj-wY49wVl1A"
   },
   "outputs": [],
   "source": [
    "use_tf2=True\n",
    "discriminator, generator, gan = build_models(use_tf2=use_tf2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkBprCbmVl1B"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dcevuZ52Vl1B"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "r_accuracies = []\n",
    "f_accuracies = []\n",
    "r_lose = []\n",
    "f_lose = []\n",
    "iteration_checkpoints = []\n",
    "\n",
    "\n",
    "def train(iterations, batch_size, sample_interval,use_tf2=False):\n",
    "\n",
    "    # Load the MNIST dataset\n",
    "    (X_train, _), (_, _) = fashion_mnist.load_data()\n",
    "\n",
    "    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
    "    X_train = X_train / 127.5 - 1.0\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Labels for real images: all ones\n",
    "    real = np.ones((batch_size, 1))\n",
    "\n",
    "    # Labels for fake images: all zeros\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    start = time.time()\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        # -------------------------\n",
    "        #  Train the Discriminator\n",
    "        # -------------------------\n",
    "\n",
    "        # Get a random batch of real images\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        # Train Discriminator\n",
    "        gen_imgs = generator(z)\n",
    "        d_loss_real,d_acc_real = train_D(discriminator,imgs, real)\n",
    "        d_loss_fake,d_acc_fake = train_D(discriminator,gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        accuracy = 0.5 * np.add(d_acc_real, d_acc_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train the Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        # Train Generator\n",
    "        g_loss = train_G(discriminator, generator, z, real)\n",
    "\n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "\n",
    "            # Save losses and accuracies so they can be plotted after training\n",
    "            losses.append((d_loss, g_loss))\n",
    "            accuracies.append(100.0 * accuracy)\n",
    "            r_accuracies.append(100.0 * d_acc_real)\n",
    "            f_accuracies.append(100.0 * d_acc_fake)\n",
    "            r_lose.append(d_loss_real)\n",
    "            f_lose.append(d_loss_fake)\n",
    "            iteration_checkpoints.append(iteration + 1)\n",
    "\n",
    "            # Output training progress\n",
    "            print(\"%d [D loss: %f, D Lose Real: %f, D Lose Fake: %f, acc.: %.2f%%, real_acc:%.2f%%, fake_acc:%.2f%%] [G loss: %f]\" %\n",
    "                  (iteration + 1, d_loss, d_loss_real, d_loss_fake, 100.0 * accuracy, 100.0 * d_acc_real, 100.0 * d_acc_fake, g_loss))\n",
    "\n",
    "            # Output a sample of generated image\n",
    "            sample_images(generator)\n",
    "            print ('Time for interval {} is {} sec'.format((iteration + 1)//sample_interval, time.time()-start))\n",
    "            start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5VQbGOtxVl1C"
   },
   "outputs": [],
   "source": [
    "def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n",
    "\n",
    "    # Sample random noise\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    # Generate images from random noise\n",
    "    gen_imgs = generator.predict(z)\n",
    "\n",
    "    # Rescale image pixel values to [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    # Set image grid\n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                            image_grid_columns,\n",
    "                            figsize=(4, 4),\n",
    "                            sharey=True,\n",
    "                            sharex=True)\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            # Output a grid of images\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O49a_7L1Vl1C"
   },
   "source": [
    "## Train the GAN and Inspect Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQT3488eVl1C"
   },
   "source": [
    "Note that the `'Discrepancy between trainable weights and collected trainable'` warning from Keras is expected. It is by design: The Generator's trainable parameters are intentionally held constant during Discriminator training, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "nI1urH6jVl1D",
    "outputId": "37bc628a-f84a-4ad5-812e-2fe4d6645467"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(16, 100), b.shape=(100, 128), m=16, n=128, k=100\n\t [[node sequential_1/dense_2/MatMul (defined at <ipython-input-11-f9175d688084>:7) ]] [Op:__inference_predict_function_268]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d52eb94a96be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-f9175d688084>\u001b[0m in \u001b[0;36msample_images\u001b[1;34m(generator, image_grid_rows, image_grid_columns)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Generate images from random noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mgen_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Rescale image pixel values to [0, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    892\u001b[0m               *args, **kwds)\n\u001b[0;32m    893\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[0;32m    895\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(16, 100), b.shape=(100, 128), m=16, n=128, k=100\n\t [[node sequential_1/dense_2/MatMul (defined at <ipython-input-11-f9175d688084>:7) ]] [Op:__inference_predict_function_268]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "sample_images(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rWF3-mtAVl1D",
    "outputId": "f9f24a3e-b166-4882-cbf6-4d0ac8c1386a"
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "iterations = 20000\n",
    "batch_size = 128\n",
    "sample_interval = 100\n",
    "# Build models\n",
    "# Train the GAN for the specified number of iterations\n",
    "train(iterations, batch_size, sample_interval,use_tf2=use_tf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "0V5EcUx5Vl1D",
    "outputId": "a5e0a76f-dd24-4b50-b03a-38518e30a7cc"
   },
   "outputs": [],
   "source": [
    "losses = np.array(losses)\n",
    "\n",
    "# Plot training losses for Discriminator and Generator\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iteration_checkpoints, losses.T[0], label=\"Discriminator loss\")\n",
    "plt.plot(iteration_checkpoints, losses.T[1], label=\"Generator loss\")\n",
    "plt.plot(iteration_checkpoints, f_lose, label=\"Discriminator lose of fake\")\n",
    "plt.plot(iteration_checkpoints, r_lose, label=\"Discriminator lose of real\")\n",
    "\n",
    "\n",
    "plt.xticks(iteration_checkpoints, rotation=90)\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "6eU1hTq_Vl1D",
    "outputId": "b3707cd8-85df-4f7e-d124-3d0433ad0629"
   },
   "outputs": [],
   "source": [
    "accuracies = np.array(accuracies)\n",
    "\n",
    "# Plot Discriminator accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iteration_checkpoints, accuracies, label=\"Discriminator accuracy\")\n",
    "plt.plot(iteration_checkpoints, f_accuracies, label=\"Discriminator accuracy of fake\")\n",
    "plt.plot(iteration_checkpoints, r_accuracies, label=\"Discriminator accuracy of real\")\n",
    "\n",
    "plt.xticks(iteration_checkpoints, rotation=90)\n",
    "plt.yticks(range(0, 100, 5))\n",
    "\n",
    "plt.title(\"Discriminator Accuracy\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_7YZ2hoVl1E"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "nqFMnpQ5Vl1E",
    "outputId": "3504a0d8-cb9f-458b-efb5-59b8f4696f40"
   },
   "outputs": [],
   "source": [
    "def evaluate(n_sample=100, use_tf2=False):\n",
    "    # Generate a batch of fake images\n",
    "    z = np.random.normal(0, 1, (n_sample, 100))\n",
    "\n",
    "    # Train Discriminator\n",
    "    if use_tf2:\n",
    "        gen_imgs = generator(z)\n",
    "    else: \n",
    "        gen_imgs = generator.predict(z)\n",
    "    real = np.ones((n_sample, 1))\n",
    "    fake = np.zeros((n_sample, 1))\n",
    "    a=accuracy(real, discriminator(gen_imgs))\n",
    "    print (\"%d%% generated images are predicted as real\"%int(a*100))\n",
    "    idx=np.argwhere(tf.reshape(discriminator(gen_imgs),-1)>0.5).reshape(-1)\n",
    "    print (idx)\n",
    "    for i in idx:\n",
    "      sel_imgs=gen_imgs[i]\n",
    "      print(discriminator(gen_imgs[i:i+1]))\n",
    "      plt.imshow(sel_imgs,cmap='gray')\n",
    "      plt.show()\n",
    "    \n",
    "evaluate(n_sample=100,use_tf2=use_tf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKn7B-pNVl1E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "WEEK4_First_GAN_D_G_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
